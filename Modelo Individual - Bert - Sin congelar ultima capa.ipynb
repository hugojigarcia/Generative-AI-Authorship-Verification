{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL8s_6Uk5YNS"
   },
   "source": [
    "Integrantes del equipo:\n",
    "- Alonso Cañas Rico\n",
    "- Hugo Jiménez García"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 256\n",
    "LAYERS_TO_TRAIN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731435422582,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "GKn1bmaa5YNW"
   },
   "outputs": [],
   "source": [
    "ai_generated_path = \"pan24-generative-authorship-news/machines\"\n",
    "human_path = \"pan24-generative-authorship-news/human.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWXWzySt5YNW"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731435422582,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "qeUPp2_A5YNX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, \n",
    "    brier_score_loss, fbeta_score\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device and warmings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\".*overflowing tokens.*\")\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50rub4dv5YNX"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1731435423264,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "_gOQsxrH5YNX",
    "outputId": "87ee1c86-3d8f-4943-e9c8-a53dd9489609"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>'The Disappearance of Gabby Petito' – A Compre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>Utah State Police Search for Gabby Petito, Tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>\"Gunshots Found in Florida Nature Preserve: A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0                           alpaca-7b.jsonl   \n",
       "1                           alpaca-7b.jsonl   \n",
       "2                           alpaca-7b.jsonl   \n",
       "3                           alpaca-7b.jsonl   \n",
       "4                           alpaca-7b.jsonl   \n",
       "...                                     ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14127  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14128  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14129  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14130  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "\n",
       "                                                      id  \\\n",
       "0      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "1      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "2      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "3      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "4      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "...                                                  ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14127  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14128  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14129  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14130  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "\n",
       "                                                    text  ai_generated  \n",
       "0      Inaugural Address: President Joseph R. Biden J...             1  \n",
       "1      Setting the Record Straight: Fact-Checking the...             1  \n",
       "2      Joe Biden Takes the Oath of Office as 46th Pre...             1  \n",
       "3      Joe Biden Takes Oath as 46th President of Unit...             1  \n",
       "4      Amanda Gorman's Inspiring Poem Celebrates Hope...             1  \n",
       "...                                                  ...           ...  \n",
       "14126  'The Disappearance of Gabby Petito' – A Compre...             1  \n",
       "14127  Utah State Police Search for Gabby Petito, Tra...             1  \n",
       "14128  McKenna's Lost Friend: Debunking the Evidence ...             1  \n",
       "14129  \"Gunshots Found in Florida Nature Preserve: A ...             1  \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...             1  \n",
       "\n",
       "[14131 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, id, text = [], [], []\n",
    "\n",
    "# Loop through every file in the directory\n",
    "for filename in os.listdir(ai_generated_path):\n",
    "    # Check if the file is a JSONL file\n",
    "    if filename.endswith('.jsonl'):\n",
    "        filepath = os.path.join(ai_generated_path, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                # Each line is a separate JSON object\n",
    "                data = json.loads(line)\n",
    "                model.append(filename)\n",
    "                id.append(data['id'])\n",
    "                text.append(data['text'])\n",
    "\n",
    "df_generated = pd.DataFrame({'model': model, 'id': id, 'text': text, 'ai_generated': 1})\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731435423265,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "N5mdYLgR5YNa",
    "outputId": "35f45c67-b70f-4884-9122-400164f7324d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                                 id  \\\n",
       "0     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "2     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "3     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "4     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "...     ...                                                ...   \n",
       "1082  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1083  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1084  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1085  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1086  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "\n",
       "                                                   text  ai_generated  \n",
       "0     Inaugural Address by President Joseph R. Biden...             0  \n",
       "1     Fact check: Biden inauguration impacted by pan...             0  \n",
       "2     Highlights from Joe Biden's 2021 inauguration\\...             0  \n",
       "3     Biden takes the helm, appeals for unity to tak...             0  \n",
       "4     'The Hill We Climb': Read Amanda Gorman's inau...             0  \n",
       "...                                                 ...           ...  \n",
       "1082  How amateur detectives on social media helped ...             0  \n",
       "1083  Authorities searching for missing 22-year-old ...             0  \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0  \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0  \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0  \n",
       "\n",
       "[1087 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id, text = [], []\n",
    "\n",
    "with open(human_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        # Each line is a separate JSON object\n",
    "        data = json.loads(line)\n",
    "        id.append(data['id'])\n",
    "        text.append(data['text'])\n",
    "\n",
    "df_human = pd.DataFrame({'model': 'Human', 'id': id, 'text': text, 'ai_generated': 0})\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1731435423554,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "SrHvBgX25YNb",
    "outputId": "a6d62806-0f0c-4cf6-85b6-24f8c5f39e91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15218 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                                 id  \\\n",
       "0     alpaca-7b.jsonl  alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "1     alpaca-7b.jsonl  alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "2     alpaca-7b.jsonl  alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "3     alpaca-7b.jsonl  alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "4     alpaca-7b.jsonl  alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "...               ...                                                ...   \n",
       "1082            Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1083            Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1084            Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1085            Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1086            Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "\n",
       "                                                   text  ai_generated  \n",
       "0     Inaugural Address: President Joseph R. Biden J...             1  \n",
       "1     Setting the Record Straight: Fact-Checking the...             1  \n",
       "2     Joe Biden Takes the Oath of Office as 46th Pre...             1  \n",
       "3     Joe Biden Takes Oath as 46th President of Unit...             1  \n",
       "4     Amanda Gorman's Inspiring Poem Celebrates Hope...             1  \n",
       "...                                                 ...           ...  \n",
       "1082  How amateur detectives on social media helped ...             0  \n",
       "1083  Authorities searching for missing 22-year-old ...             0  \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0  \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0  \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0  \n",
       "\n",
       "[15218 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_generated, df_human])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make combinations of text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9506, 5)\n",
      "val shape: (1904, 5)\n",
      "test shape: (3808, 5)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "val_size = 0.125\n",
    "_adjusted_val_size = val_size / (1 - test_size)\n",
    "\n",
    "# Extraer el segundo y tercer segmento de los IDs\n",
    "df['base_id'] = df['id'].apply(lambda x: '/'.join(x.split('/')[1:]))  # Coger los ids sin la parte que identifica al autor del fragmento de texto.\n",
    "\n",
    "# Paso 1: Dividir los datos según los `base_id`\n",
    "base_ids = df['base_id'].unique()\n",
    "train_base_ids, test_base_ids = train_test_split(base_ids, test_size=test_size, random_state=1337)\n",
    "train_base_ids, val_base_ids = train_test_split(train_base_ids, test_size=_adjusted_val_size, random_state=1337) \n",
    "\n",
    "# Crear DataFrames por conjunto\n",
    "train = df[df['base_id'].isin(train_base_ids)]\n",
    "val = df[df['base_id'].isin(val_base_ids)]\n",
    "test = df[df['base_id'].isin(test_base_ids)]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"val shape: {val.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combinations_within_id(df):\n",
    "    # Lista para almacenar las combinaciones de cada `base_id`\n",
    "    combinations = []\n",
    "    \n",
    "    # Iterar sobre cada `base_id`\n",
    "    for _, group in df.groupby('base_id'):\n",
    "        # Filtrar textos humanos e IA dentro del grupo\n",
    "        df_human = group[group['ai_generated'] == 0][['text']].reset_index(drop=True)\n",
    "        df_ia = group[group['ai_generated'] == 1][['text']].reset_index(drop=True)\n",
    "        \n",
    "        # Producto cartesiano dentro del `base_id`\n",
    "        cartesian_df = df_human.merge(df_ia, how='cross', suffixes=('_human', '_ia'))\n",
    "        cartesian_df = cartesian_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Crear las dos disposiciones\n",
    "        total_combinations = len(cartesian_df)\n",
    "        \n",
    "        half_1 = cartesian_df.iloc[:total_combinations // 2].copy()\n",
    "        half_1['comment_text_1'] = half_1['text_human']\n",
    "        half_1['comment_text_2'] = half_1['text_ia']\n",
    "        half_1['list'] = 0  # Etiqueta 0\n",
    "        \n",
    "        half_2 = cartesian_df.iloc[total_combinations // 2:].copy()\n",
    "        half_2['comment_text_1'] = half_2['text_ia']\n",
    "        half_2['comment_text_2'] = half_2['text_human']\n",
    "        half_2['list'] = 1  # Etiqueta 1\n",
    "        \n",
    "        # Combinar y agregar al resultado final\n",
    "        balanced_df = pd.concat([half_1, half_2], ignore_index=True)\n",
    "        combinations.append(balanced_df)\n",
    "    \n",
    "    # Concatenar todas las combinaciones y barajar\n",
    "    return pd.concat(combinations, ignore_index=True).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar combinaciones restringidas por `id` para cada conjunto\n",
    "train = create_combinations_within_id(train)\n",
    "val = create_combinations_within_id(val)\n",
    "test = create_combinations_within_id(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (8827, 5) / Text on comment_text_1 is human-generated: 4074 - Text on comment_text_2 is human-generated: 4753\n",
      "val shape: (1768, 5) / Text on comment_text_1 is human-generated: 816 - Text on comment_text_2 is human-generated: 952\n",
      "test shape: (3536, 5) / Text on comment_text_1 is human-generated: 1632 - Text on comment_text_2 is human-generated: 1904\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions\n",
    "print(f\"train shape: {train.shape} / Text on comment_text_1 is human-generated: {train['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {train['list'].value_counts()[1]}\")\n",
    "print(f\"val shape: {val.shape} / Text on comment_text_1 is human-generated: {val['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {val['list'].value_counts()[1]}\")\n",
    "print(f\"test shape: {test.shape} / Text on comment_text_1 is human-generated: {test['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {test['list'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG82NuUA5YNc"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1731435423898,
     "user": {
      "displayName": "Hugo Jiménez García",
      "userId": "06485726344686732927"
     },
     "user_tz": -60
    },
    "id": "Bz17SJ3D6WIm",
    "outputId": "bfc6f612-e730-4bd5-be77-679cb9880583"
   },
   "outputs": [],
   "source": [
    "# Tokenizador y modelo\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "individual_model =  BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight: requires_grad = False\n",
      "embeddings.position_embeddings.weight: requires_grad = False\n",
      "embeddings.token_type_embeddings.weight: requires_grad = False\n",
      "embeddings.LayerNorm.weight: requires_grad = False\n",
      "embeddings.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.0.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.0.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.0.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.0.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.0.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.0.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.0.output.dense.weight: requires_grad = False\n",
      "encoder.layer.0.output.dense.bias: requires_grad = False\n",
      "encoder.layer.0.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.0.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.1.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.1.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.1.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.1.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.1.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.1.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.1.output.dense.weight: requires_grad = False\n",
      "encoder.layer.1.output.dense.bias: requires_grad = False\n",
      "encoder.layer.1.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.1.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.2.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.2.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.2.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.2.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.2.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.2.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.2.output.dense.weight: requires_grad = False\n",
      "encoder.layer.2.output.dense.bias: requires_grad = False\n",
      "encoder.layer.2.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.2.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.3.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.3.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.3.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.3.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.3.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.3.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.3.output.dense.weight: requires_grad = False\n",
      "encoder.layer.3.output.dense.bias: requires_grad = False\n",
      "encoder.layer.3.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.3.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.4.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.4.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.4.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.4.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.4.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.4.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.4.output.dense.weight: requires_grad = False\n",
      "encoder.layer.4.output.dense.bias: requires_grad = False\n",
      "encoder.layer.4.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.4.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.5.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.5.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.5.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.5.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.5.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.5.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.5.output.dense.weight: requires_grad = False\n",
      "encoder.layer.5.output.dense.bias: requires_grad = False\n",
      "encoder.layer.5.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.5.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.6.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.6.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.6.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.6.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.6.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.6.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.6.output.dense.weight: requires_grad = False\n",
      "encoder.layer.6.output.dense.bias: requires_grad = False\n",
      "encoder.layer.6.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.6.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.7.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.7.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.7.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.7.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.7.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.7.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.7.output.dense.weight: requires_grad = False\n",
      "encoder.layer.7.output.dense.bias: requires_grad = False\n",
      "encoder.layer.7.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.7.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.8.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.8.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.8.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.8.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.8.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.8.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.8.output.dense.weight: requires_grad = False\n",
      "encoder.layer.8.output.dense.bias: requires_grad = False\n",
      "encoder.layer.8.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.8.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.9.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.9.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.9.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.9.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.9.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.9.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.9.output.dense.weight: requires_grad = False\n",
      "encoder.layer.9.output.dense.bias: requires_grad = False\n",
      "encoder.layer.9.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.9.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.10.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.10.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.10.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.10.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.10.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.10.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.10.output.dense.weight: requires_grad = False\n",
      "encoder.layer.10.output.dense.bias: requires_grad = False\n",
      "encoder.layer.10.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.10.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.11.attention.self.query.weight: requires_grad = True\n",
      "encoder.layer.11.attention.self.query.bias: requires_grad = True\n",
      "encoder.layer.11.attention.self.key.weight: requires_grad = True\n",
      "encoder.layer.11.attention.self.key.bias: requires_grad = True\n",
      "encoder.layer.11.attention.self.value.weight: requires_grad = True\n",
      "encoder.layer.11.attention.self.value.bias: requires_grad = True\n",
      "encoder.layer.11.attention.output.dense.weight: requires_grad = True\n",
      "encoder.layer.11.attention.output.dense.bias: requires_grad = True\n",
      "encoder.layer.11.attention.output.LayerNorm.weight: requires_grad = True\n",
      "encoder.layer.11.attention.output.LayerNorm.bias: requires_grad = True\n",
      "encoder.layer.11.intermediate.dense.weight: requires_grad = True\n",
      "encoder.layer.11.intermediate.dense.bias: requires_grad = True\n",
      "encoder.layer.11.output.dense.weight: requires_grad = True\n",
      "encoder.layer.11.output.dense.bias: requires_grad = True\n",
      "encoder.layer.11.output.LayerNorm.weight: requires_grad = True\n",
      "encoder.layer.11.output.LayerNorm.bias: requires_grad = True\n",
      "pooler.dense.weight: requires_grad = True\n",
      "pooler.dense.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "for param in individual_model.parameters():\n",
    "    param.requires_grad = False\n",
    "if LAYERS_TO_TRAIN > 0:\n",
    "    for layer in individual_model.encoder.layer[-LAYERS_TO_TRAIN:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "for param in individual_model.pooler.dense.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify that only the classifier layer is trainable\n",
    "for name, param in individual_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (l4): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerClass(torch.nn.Module):\n",
    "    def __init__(self, individual_model):\n",
    "        super(TransformerClass, self).__init__()\n",
    "        self.l1 = individual_model\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 1)\n",
    "        self.l4 = torch.nn.Sigmoid()\n",
    "    \n",
    "    def __predict(self, ids, mask, token_type_ids):\n",
    "        x = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids).last_hidden_state[:, 0]\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, ids_0, mask_0, token_type_ids_0, ids_1, mask_1, token_type_ids_1):\n",
    "        p1_human = self.__predict(ids_0, mask_0, token_type_ids_0)\n",
    "        p2_human = self.__predict(ids_1, mask_1, token_type_ids_1)\n",
    "        return p2_human / (p1_human + p2_human)\n",
    "\n",
    "\n",
    "model = TransformerClass(individual_model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text_1 = dataframe.comment_text_1\n",
    "        self.comment_text_2 = dataframe.comment_text_2\n",
    "        self.targets = self.data.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text_1 = str(self.comment_text_1[index])\n",
    "        comment_text_1 = \" \".join(comment_text_1.split())\n",
    "        comment_text_2 = str(self.comment_text_2[index])\n",
    "        comment_text_2 = \" \".join(comment_text_2.split())\n",
    "        inputs0 = self.tokenizer(comment_text_1, \n",
    "                                max_length=self.max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_token_type_ids=True)\n",
    "        inputs1 = self.tokenizer(comment_text_2,\n",
    "                                max_length=self.max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_token_type_ids=True)\n",
    "        return {\n",
    "            'ids_0': torch.tensor(inputs0.input_ids, dtype=torch.long),\n",
    "            'mask_0': torch.tensor(inputs0.attention_mask, dtype=torch.long),\n",
    "            'token_type_ids_0': torch.tensor(inputs0.token_type_ids, dtype=torch.long),\n",
    "            'ids_1': torch.tensor(inputs1.input_ids, dtype=torch.long),\n",
    "            'mask_1': torch.tensor(inputs1.attention_mask, dtype=torch.long),\n",
    "            'token_type_ids_1': torch.tensor(inputs1.token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia el dataset\n",
    "train_dataset = CustomDataset(dataframe=train, tokenizer=tokenizer, max_len=512)\n",
    "val_dataset = CustomDataset(dataframe=val, tokenizer=tokenizer, max_len=512)\n",
    "test_dataset = CustomDataset(dataframe=test, tokenizer=tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and metrics methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_at_1(targets, preds):\n",
    "    \"\"\"\n",
    "    Calculates the C@1 metric:\n",
    "    - Non-answers (predictions marked as -1) are given a score of 0.5.\n",
    "    - Remaining cases are scored based on accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        targets (np.array): Ground truth labels.\n",
    "        preds (np.array): Predictions, where -1 indicates a non-answer.\n",
    "    \n",
    "    Returns:\n",
    "        float: C@1 metric.\n",
    "    \"\"\"\n",
    "    correct = (targets == preds)  # Boolean array for correct predictions\n",
    "    unanswered = preds == -1     # Boolean array for non-answers\n",
    "    \n",
    "    num_correct = correct.sum()\n",
    "    num_total = len(targets)\n",
    "    num_unanswered = unanswered.sum()\n",
    "    \n",
    "    return (num_correct + num_unanswered * 0.5) / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento\n",
    "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Use tqdm to wrap the loader for a progress bar\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=True):\n",
    "        labels = batch['labels'].unsqueeze(1).to(device).float()\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "# Función de evaluación\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, targets, probabilities = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            labels = batch['labels'].unsqueeze(1).float()\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            outputs = model(**batch)\n",
    "            probabilities.extend(outputs.cpu().numpy())\n",
    "            preds.extend(torch.round(outputs).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    targets = np.array(targets).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    probabilities = np.array(probabilities).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    roc_auc = roc_auc_score(targets, probabilities)\n",
    "    brier = brier_score_loss(targets, probabilities)\n",
    "    f1 = f1_score(targets, preds)\n",
    "    f05u = fbeta_score(targets, preds, beta=0.5)\n",
    "    c1 = c_at_1(targets, preds)\n",
    "    mean = np.mean([roc_auc, 1-brier, c1, f1, f05u])\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(targets, preds),\n",
    "        \"roc-auc\": roc_auc,\n",
    "        \"brier\": brier,\n",
    "        \"c@1\": c1,\n",
    "        \"f1\": f1,\n",
    "        \"f05u\": f05u,\n",
    "        \"mean\": mean,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 35/35 [1:58:37<00:00, 203.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Saving model\n",
      "Epoch 1/10\n",
      "Train Loss: 0.4985\n",
      "Starting Epoch 2/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 35/35 [2:07:28<00:00, 218.54s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Saving model\n",
      "Epoch 2/10\n",
      "Train Loss: 0.1269\n",
      "Starting Epoch 3/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 35/35 [2:05:16<00:00, 214.76s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Saving model\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0474\n",
      "Starting Epoch 4/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 35/35 [2:10:19<00:00, 223.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Saving model\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0262\n",
      "Starting Epoch 5/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 35/35 [3:02:43<00:00, 313.24s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Saving model\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0174\n",
      "Starting Epoch 6/10\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_metrics\": [],\n",
    "    \"val_metrics\": []\n",
    "}\n",
    "\n",
    "save_path = f\"models/models_individual_bert/fine_tuned_model_{EPOCHS}_epochs_{LEARNING_RATE}_lr_{LAYERS_TO_TRAIN}_layers_{BATCH_SIZE}_batch_size\"\n",
    "\n",
    "\n",
    "# Entrenamiento y validación\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"* Training\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "\n",
    "    print(\"* Saving model\")\n",
    "    _epoch_save_path = f\"{save_path}_checkpoint_{epoch + 1}.pth\"\n",
    "    torch.save(model, _epoch_save_path)\n",
    "\n",
    "    print(\"* Calculating metrics for training\")\n",
    "    train_metrics = evaluate(model, train_loader, device)\n",
    "    print(\"* Calculating metrics for validation\")\n",
    "    val_metrics = evaluate(model, val_loader, device)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_metrics\"].append(train_metrics)\n",
    "    history[\"val_metrics\"].append(val_metrics)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(\"Train Metrics:\")\n",
    "    for metric_name, value in train_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    for metric_name, value in val_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = history[\"val_metrics\"][0].keys()\n",
    "epochs = list(range(1, len(history[\"val_metrics\"]) + 1))\n",
    "\n",
    "train_values = {name: [epoch.get(name, None) for epoch in history[\"train_metrics\"]] for name in metric_names}\n",
    "val_values = {name: [epoch.get(name, None) for epoch in history[\"val_metrics\"]] for name in metric_names}\n",
    "\n",
    "num_subplots = len(metric_names) + 1  # Number of metrics + train loss\n",
    "plt.figure(figsize=(14, 4 * num_subplots))  # Increase height proportional to the number of plots\n",
    "\n",
    "# Plot train loss\n",
    "plt.subplot(num_subplots, 1, 1)\n",
    "\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", marker=\"o\", color=\"blue\")\n",
    "plt.title(\"Train Loss Across Epochs\", fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plotting each metric in a separate graph\n",
    "for idx, metric in enumerate(metric_names):\n",
    "    plt.subplot(len(metric_names) + 1, 1, idx + 2)  # Adjust index for additional loss plot\n",
    "    plt.plot(epochs, train_values[metric], label=f'Train - {metric}', marker='o')\n",
    "    plt.plot(epochs, val_values[metric], label=f'Val - {metric}', marker='x')\n",
    "    plt.title(f\"{metric} Across Epochs\", fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(f\"{metric} Value\", fontsize=12)\n",
    "    plt.xticks(epochs)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "  accuracy: 0.9963235294117647\n",
      "  roc-auc: 0.9998152753748558\n",
      "  brier: 0.9925765454764386\n",
      "  c@1: 0.9963235294117647\n",
      "  f1: 0.9965852377199895\n",
      "  f05u: 0.996742328709542\n",
      "  mean: 0.9964085833385182\n"
     ]
    }
   ],
   "source": [
    "# Evaluación final en el conjunto de prueba\n",
    "test_metrics = evaluate(model, test_loader, device)\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "for metric_name, value in test_metrics.items():\n",
    "    print(f\"  {metric_name}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
