{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modelos Contrastivos (CLIP-like)\n",
    "Entrena un modelo basado en contraste, donde el objetivo es minimizar la distancia entre embeddings de texto humano y maximizar la distancia entre humano y generado por IA.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Permite aprender representaciones robustas.\n",
    "Se puede usar junto con un clasificador simple para la predicción final.\n",
    "Ejemplo de entrenamiento contrastivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 256\n",
    "LAYERS_TO_TRAIN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alonso\\Documents\\## UPM\\MASTER\\NLP\\practica\\NLP\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_generated_path = \"pan24-generative-authorship-news/machines\"\n",
    "human_path = \"pan24-generative-authorship-news/human.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*overflowing tokens.*\")\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>'The Disappearance of Gabby Petito' – A Compre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>Utah State Police Search for Gabby Petito, Tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>\"Gunshots Found in Florida Nature Preserve: A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0                           alpaca-7b.jsonl   \n",
       "1                           alpaca-7b.jsonl   \n",
       "2                           alpaca-7b.jsonl   \n",
       "3                           alpaca-7b.jsonl   \n",
       "4                           alpaca-7b.jsonl   \n",
       "...                                     ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14127  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14128  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14129  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14130  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "\n",
       "                                                      id  \\\n",
       "0      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "1      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "2      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "3      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "4      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "...                                                  ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14127  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14128  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14129  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14130  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "\n",
       "                                                    text  ai_generated  \n",
       "0      Inaugural Address: President Joseph R. Biden J...             1  \n",
       "1      Setting the Record Straight: Fact-Checking the...             1  \n",
       "2      Joe Biden Takes the Oath of Office as 46th Pre...             1  \n",
       "3      Joe Biden Takes Oath as 46th President of Unit...             1  \n",
       "4      Amanda Gorman's Inspiring Poem Celebrates Hope...             1  \n",
       "...                                                  ...           ...  \n",
       "14126  'The Disappearance of Gabby Petito' – A Compre...             1  \n",
       "14127  Utah State Police Search for Gabby Petito, Tra...             1  \n",
       "14128  McKenna's Lost Friend: Debunking the Evidence ...             1  \n",
       "14129  \"Gunshots Found in Florida Nature Preserve: A ...             1  \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...             1  \n",
       "\n",
       "[14131 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, id, text = [], [], []\n",
    "\n",
    "# Loop through every file in the directory\n",
    "for filename in os.listdir(ai_generated_path):\n",
    "    # Check if the file is a JSONL file\n",
    "    if filename.endswith('.jsonl'):\n",
    "        filepath = os.path.join(ai_generated_path, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                # Each line is a separate JSON object\n",
    "                data = json.loads(line)\n",
    "                model.append(filename)\n",
    "                id.append(data['id'])\n",
    "                text.append(data['text'])\n",
    "\n",
    "df_generated = pd.DataFrame({'model': model, 'id': id, 'text': text, 'ai_generated': 1})\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                                 id  \\\n",
       "0     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "2     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "3     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "4     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "...     ...                                                ...   \n",
       "1082  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1083  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1084  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1085  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1086  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "\n",
       "                                                   text  ai_generated  \n",
       "0     Inaugural Address by President Joseph R. Biden...             0  \n",
       "1     Fact check: Biden inauguration impacted by pan...             0  \n",
       "2     Highlights from Joe Biden's 2021 inauguration\\...             0  \n",
       "3     Biden takes the helm, appeals for unity to tak...             0  \n",
       "4     'The Hill We Climb': Read Amanda Gorman's inau...             0  \n",
       "...                                                 ...           ...  \n",
       "1082  How amateur detectives on social media helped ...             0  \n",
       "1083  Authorities searching for missing 22-year-old ...             0  \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0  \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0  \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0  \n",
       "\n",
       "[1087 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id, text = [], []\n",
    "\n",
    "with open(human_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        # Each line is a separate JSON object\n",
    "        data = json.loads(line)\n",
    "        id.append(data['id'])\n",
    "        text.append(data['text'])\n",
    "\n",
    "df_human = pd.DataFrame({'model': 'Human', 'id': id, 'text': text, 'ai_generated': 0})\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ai_generated  \\\n",
       "0     Inaugural Address: President Joseph R. Biden J...             1   \n",
       "1     Setting the Record Straight: Fact-Checking the...             1   \n",
       "2     Joe Biden Takes the Oath of Office as 46th Pre...             1   \n",
       "3     Joe Biden Takes Oath as 46th President of Unit...             1   \n",
       "4     Amanda Gorman's Inspiring Poem Celebrates Hope...             1   \n",
       "...                                                 ...           ...   \n",
       "1082  How amateur detectives on social media helped ...             0   \n",
       "1083  Authorities searching for missing 22-year-old ...             0   \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0   \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0   \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "\n",
       "                                                     id  \n",
       "0     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "1     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "2     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "3     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "4     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "...                                                 ...  \n",
       "1082  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1083  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1084  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1085  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1086  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "\n",
       "[15218 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_generated, df_human])[['text', 'ai_generated', 'id']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data - Combinaciones únicamente del mismo id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9506, 4)\n",
      "val shape: (1904, 4)\n",
      "test shape: (3808, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "test_size = 0.25\n",
    "val_size = 0.125\n",
    "_adjusted_val_size = val_size / (1 - test_size)\n",
    "\n",
    "# Extraer el segundo y tercer segmento de los IDs\n",
    "df['base_id'] = df['id'].apply(lambda x: '/'.join(x.split('/')[1:]))  # Coger los ids sin la parte que identifica al autor del fragmento de texto.\n",
    "\n",
    "# Paso 1: Dividir los datos según los `base_id`\n",
    "base_ids = df['base_id'].unique()\n",
    "train_base_ids, test_base_ids = train_test_split(base_ids, test_size=test_size, random_state=1337)\n",
    "train_base_ids, val_base_ids = train_test_split(train_base_ids, test_size=_adjusted_val_size, random_state=1337) \n",
    "\n",
    "# Crear DataFrames por conjunto\n",
    "train = df[df['base_id'].isin(train_base_ids)]\n",
    "val = df[df['base_id'].isin(val_base_ids)]\n",
    "test = df[df['base_id'].isin(test_base_ids)]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"val shape: {val.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combinations_within_id(df):\n",
    "    # Lista para almacenar las combinaciones de cada `base_id`\n",
    "    combinations = []\n",
    "    \n",
    "    # Iterar sobre cada `base_id`\n",
    "    for _, group in df.groupby('base_id'):\n",
    "        # Filtrar textos humanos e IA dentro del grupo\n",
    "        df_human = group[group['ai_generated'] == 0][['text']].reset_index(drop=True)\n",
    "        df_ia = group[group['ai_generated'] == 1][['text']].reset_index(drop=True)\n",
    "        \n",
    "        # Producto cartesiano dentro del `base_id`\n",
    "        cartesian_df = df_human.merge(df_ia, how='cross', suffixes=('_human', '_ia'))\n",
    "        cartesian_df = cartesian_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Crear las dos disposiciones\n",
    "        total_combinations = len(cartesian_df)\n",
    "        \n",
    "        half_1 = cartesian_df.iloc[:total_combinations // 2].copy()\n",
    "        half_1['comment_text_1'] = half_1['text_human']\n",
    "        half_1['comment_text_2'] = half_1['text_ia']\n",
    "        half_1['list'] = 0  # Etiqueta 0\n",
    "        \n",
    "        half_2 = cartesian_df.iloc[total_combinations // 2:].copy()\n",
    "        half_2['comment_text_1'] = half_2['text_ia']\n",
    "        half_2['comment_text_2'] = half_2['text_human']\n",
    "        half_2['list'] = 1  # Etiqueta 1\n",
    "        \n",
    "        # Combinar y agregar al resultado final\n",
    "        balanced_df = pd.concat([half_1, half_2], ignore_index=True)\n",
    "        combinations.append(balanced_df)\n",
    "    \n",
    "    # Concatenar todas las combinaciones y barajar\n",
    "    return pd.concat(combinations, ignore_index=True).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar combinaciones restringidas por `id` para cada conjunto\n",
    "train = create_combinations_within_id(train)\n",
    "val = create_combinations_within_id(val)\n",
    "test = create_combinations_within_id(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (8827, 5) / Text on comment_text_1 is human-generated: 4074 - Text on comment_text_2 is human-generated: 4753\n",
      "val shape: (1768, 5) / Text on comment_text_1 is human-generated: 816 - Text on comment_text_2 is human-generated: 952\n",
      "test shape: (3536, 5) / Text on comment_text_1 is human-generated: 1632 - Text on comment_text_2 is human-generated: 1904\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions\n",
    "print(f\"train shape: {train.shape} / Text on comment_text_1 is human-generated: {train['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {train['list'].value_counts()[1]}\")\n",
    "print(f\"val shape: {val.shape} / Text on comment_text_1 is human-generated: {val['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {val['list'].value_counts()[1]}\")\n",
    "print(f\"test shape: {test.shape} / Text on comment_text_1 is human-generated: {test['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {test['list'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Tokenizador y modelo\n",
    "model_name = \"Lau123/distilbert-base-uncased-detect_ai_generated_text\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# individual_model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "individual_model = DistilBertModel.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight: requires_grad = False\n",
      "embeddings.position_embeddings.weight: requires_grad = False\n",
      "embeddings.LayerNorm.weight: requires_grad = False\n",
      "embeddings.LayerNorm.bias: requires_grad = False\n",
      "transformer.layer.0.attention.q_lin.weight: requires_grad = False\n",
      "transformer.layer.0.attention.q_lin.bias: requires_grad = False\n",
      "transformer.layer.0.attention.k_lin.weight: requires_grad = False\n",
      "transformer.layer.0.attention.k_lin.bias: requires_grad = False\n",
      "transformer.layer.0.attention.v_lin.weight: requires_grad = False\n",
      "transformer.layer.0.attention.v_lin.bias: requires_grad = False\n",
      "transformer.layer.0.attention.out_lin.weight: requires_grad = False\n",
      "transformer.layer.0.attention.out_lin.bias: requires_grad = False\n",
      "transformer.layer.0.sa_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.0.sa_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.0.ffn.lin1.weight: requires_grad = False\n",
      "transformer.layer.0.ffn.lin1.bias: requires_grad = False\n",
      "transformer.layer.0.ffn.lin2.weight: requires_grad = False\n",
      "transformer.layer.0.ffn.lin2.bias: requires_grad = False\n",
      "transformer.layer.0.output_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.0.output_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.1.attention.q_lin.weight: requires_grad = False\n",
      "transformer.layer.1.attention.q_lin.bias: requires_grad = False\n",
      "transformer.layer.1.attention.k_lin.weight: requires_grad = False\n",
      "transformer.layer.1.attention.k_lin.bias: requires_grad = False\n",
      "transformer.layer.1.attention.v_lin.weight: requires_grad = False\n",
      "transformer.layer.1.attention.v_lin.bias: requires_grad = False\n",
      "transformer.layer.1.attention.out_lin.weight: requires_grad = False\n",
      "transformer.layer.1.attention.out_lin.bias: requires_grad = False\n",
      "transformer.layer.1.sa_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.1.sa_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.1.ffn.lin1.weight: requires_grad = False\n",
      "transformer.layer.1.ffn.lin1.bias: requires_grad = False\n",
      "transformer.layer.1.ffn.lin2.weight: requires_grad = False\n",
      "transformer.layer.1.ffn.lin2.bias: requires_grad = False\n",
      "transformer.layer.1.output_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.1.output_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.2.attention.q_lin.weight: requires_grad = False\n",
      "transformer.layer.2.attention.q_lin.bias: requires_grad = False\n",
      "transformer.layer.2.attention.k_lin.weight: requires_grad = False\n",
      "transformer.layer.2.attention.k_lin.bias: requires_grad = False\n",
      "transformer.layer.2.attention.v_lin.weight: requires_grad = False\n",
      "transformer.layer.2.attention.v_lin.bias: requires_grad = False\n",
      "transformer.layer.2.attention.out_lin.weight: requires_grad = False\n",
      "transformer.layer.2.attention.out_lin.bias: requires_grad = False\n",
      "transformer.layer.2.sa_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.2.sa_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.2.ffn.lin1.weight: requires_grad = False\n",
      "transformer.layer.2.ffn.lin1.bias: requires_grad = False\n",
      "transformer.layer.2.ffn.lin2.weight: requires_grad = False\n",
      "transformer.layer.2.ffn.lin2.bias: requires_grad = False\n",
      "transformer.layer.2.output_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.2.output_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.3.attention.q_lin.weight: requires_grad = False\n",
      "transformer.layer.3.attention.q_lin.bias: requires_grad = False\n",
      "transformer.layer.3.attention.k_lin.weight: requires_grad = False\n",
      "transformer.layer.3.attention.k_lin.bias: requires_grad = False\n",
      "transformer.layer.3.attention.v_lin.weight: requires_grad = False\n",
      "transformer.layer.3.attention.v_lin.bias: requires_grad = False\n",
      "transformer.layer.3.attention.out_lin.weight: requires_grad = False\n",
      "transformer.layer.3.attention.out_lin.bias: requires_grad = False\n",
      "transformer.layer.3.sa_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.3.sa_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.3.ffn.lin1.weight: requires_grad = False\n",
      "transformer.layer.3.ffn.lin1.bias: requires_grad = False\n",
      "transformer.layer.3.ffn.lin2.weight: requires_grad = False\n",
      "transformer.layer.3.ffn.lin2.bias: requires_grad = False\n",
      "transformer.layer.3.output_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.3.output_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.4.attention.q_lin.weight: requires_grad = False\n",
      "transformer.layer.4.attention.q_lin.bias: requires_grad = False\n",
      "transformer.layer.4.attention.k_lin.weight: requires_grad = False\n",
      "transformer.layer.4.attention.k_lin.bias: requires_grad = False\n",
      "transformer.layer.4.attention.v_lin.weight: requires_grad = False\n",
      "transformer.layer.4.attention.v_lin.bias: requires_grad = False\n",
      "transformer.layer.4.attention.out_lin.weight: requires_grad = False\n",
      "transformer.layer.4.attention.out_lin.bias: requires_grad = False\n",
      "transformer.layer.4.sa_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.4.sa_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.4.ffn.lin1.weight: requires_grad = False\n",
      "transformer.layer.4.ffn.lin1.bias: requires_grad = False\n",
      "transformer.layer.4.ffn.lin2.weight: requires_grad = False\n",
      "transformer.layer.4.ffn.lin2.bias: requires_grad = False\n",
      "transformer.layer.4.output_layer_norm.weight: requires_grad = False\n",
      "transformer.layer.4.output_layer_norm.bias: requires_grad = False\n",
      "transformer.layer.5.attention.q_lin.weight: requires_grad = True\n",
      "transformer.layer.5.attention.q_lin.bias: requires_grad = True\n",
      "transformer.layer.5.attention.k_lin.weight: requires_grad = True\n",
      "transformer.layer.5.attention.k_lin.bias: requires_grad = True\n",
      "transformer.layer.5.attention.v_lin.weight: requires_grad = True\n",
      "transformer.layer.5.attention.v_lin.bias: requires_grad = True\n",
      "transformer.layer.5.attention.out_lin.weight: requires_grad = True\n",
      "transformer.layer.5.attention.out_lin.bias: requires_grad = True\n",
      "transformer.layer.5.sa_layer_norm.weight: requires_grad = True\n",
      "transformer.layer.5.sa_layer_norm.bias: requires_grad = True\n",
      "transformer.layer.5.ffn.lin1.weight: requires_grad = True\n",
      "transformer.layer.5.ffn.lin1.bias: requires_grad = True\n",
      "transformer.layer.5.ffn.lin2.weight: requires_grad = True\n",
      "transformer.layer.5.ffn.lin2.bias: requires_grad = True\n",
      "transformer.layer.5.output_layer_norm.weight: requires_grad = True\n",
      "transformer.layer.5.output_layer_norm.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "for param in individual_model.parameters():\n",
    "    param.requires_grad = False\n",
    "if LAYERS_TO_TRAIN > 0:\n",
    "    for layer in individual_model.transformer.layer[-LAYERS_TO_TRAIN:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Verify that only the classifier layer is trainable\n",
    "for name, param in individual_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndividualTransformer(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (l2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (l3): Dropout(p=0.1, inplace=False)\n",
       "  (l4): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IndividualTransformer(torch.nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(IndividualTransformer, self).__init__()\n",
    "        self.l1 = bert_model  # Modelo BERT o similar\n",
    "        self.l2 = torch.nn.Linear(768, 768)  # Proyección del embedding\n",
    "        self.l3 = torch.nn.Dropout(0.1)  # Regularización dropout\n",
    "        self.l4 = torch.nn.Linear(768, 1)  # Salida de un solo valor (clasificación binaria)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # Generar embeddings para el texto de entrada\n",
    "        embed = self.l1(ids, attention_mask=mask).last_hidden_state[:, 0]\n",
    "        \n",
    "        # Aplicar capas adicionales\n",
    "        embed = F.gelu(self.l3(self.l2(embed)))  # Aplicar proyección y activación GELU\n",
    "        \n",
    "        # Realizar la clasificación binaria usando sigmoid\n",
    "        logits = self.l4(embed)  # Salida no activada\n",
    "        prediction = torch.sigmoid(logits)  # Aplicar sigmoid para obtener la probabilidad\n",
    "        \n",
    "        return prediction  # Devuelve la probabilidad de clase 1 (0 a 1)\n",
    "\n",
    "# Inicializar modelo\n",
    "model = IndividualTransformer(individual_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alonso\\Documents\\## UPM\\MASTER\\NLP\\practica\\NLP\\venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text_1 = dataframe.comment_text_1\n",
    "        self.comment_text_2 = dataframe.comment_text_2\n",
    "        self.targets = self.data.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text_1 = str(self.comment_text_1[index])\n",
    "        comment_text_1 = \" \".join(comment_text_1.split())\n",
    "        comment_text_2 = str(self.comment_text_2[index])\n",
    "        comment_text_2 = \" \".join(comment_text_2.split())\n",
    "\n",
    "        inputs = self.tokenizer(comment_text_1,\n",
    "                                comment_text_2,\n",
    "                                max_length=self.max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                # truncation=\"only_second\",\n",
    "                                # truncation=\"only_first\",\n",
    "                                # truncation=\"longest_first\",\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_token_type_ids=True,)\n",
    "                                # return_overflowing_tokens=True)\n",
    "                                # return_overflowing_tokens=False)\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs.input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs.attention_mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs.token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia el dataset\n",
    "train_dataset = CustomDataset(dataframe=train, tokenizer=tokenizer, max_len=512)\n",
    "val_dataset = CustomDataset(dataframe=val, tokenizer=tokenizer, max_len=512)\n",
    "test_dataset = CustomDataset(dataframe=test, tokenizer=tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_at_1(targets, preds):\n",
    "    \"\"\"\n",
    "    Calculates the C@1 metric:\n",
    "    - Non-answers (predictions marked as -1) are given a score of 0.5.\n",
    "    - Remaining cases are scored based on accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        targets (np.array): Ground truth labels.\n",
    "        preds (np.array): Predictions, where -1 indicates a non-answer.\n",
    "    \n",
    "    Returns:\n",
    "        float: C@1 metric.\n",
    "    \"\"\"\n",
    "    correct = (targets == preds)  # Boolean array for correct predictions\n",
    "    unanswered = preds == -1     # Boolean array for non-answers\n",
    "    \n",
    "    num_correct = correct.sum()\n",
    "    num_total = len(targets)\n",
    "    num_unanswered = unanswered.sum()\n",
    "    \n",
    "    return (num_correct + num_unanswered * 0.5) / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, brier_score_loss, fbeta_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Use tqdm to wrap the loader for a progress bar\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=True):\n",
    "        labels = batch['labels'].unsqueeze(1).to(device).float()\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Función de evaluación\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, targets, probabilities = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            labels = batch['labels'].unsqueeze(1).float()\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            outputs = model(**batch)\n",
    "            probabilities.extend(outputs.cpu().numpy())\n",
    "            preds.extend(torch.round(outputs).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    targets = np.array(targets).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    probabilities = np.array(probabilities).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    roc_auc = roc_auc_score(targets, probabilities)\n",
    "    brier = brier_score_loss(targets, probabilities)\n",
    "    f1 = f1_score(targets, preds)\n",
    "    f05u = fbeta_score(targets, preds, beta=0.5)\n",
    "    c1 = c_at_1(targets, preds)\n",
    "    mean = np.mean([roc_auc, brier, c1, f1, f05u])\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(targets, preds),\n",
    "        \"roc-auc\": roc_auc,\n",
    "        \"brier\": brier,\n",
    "        \"c@1\": c1,\n",
    "        \"f1\": f1,\n",
    "        \"f05u\": f05u,\n",
    "        \"mean\": mean,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/20\n",
      "* Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 29/35 [01:29<00:17,  2.89s/it]"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_metrics\": [],\n",
    "    \"val_metrics\": []\n",
    "}\n",
    "\n",
    "save_path = f\"models/models_individual_concatenate_embeddings/distil-bert-base/fine_tuned_model_{EPOCHS}_epochs_{LEARNING_RATE}_lr_{LAYERS_TO_TRAIN}_layers_{BATCH_SIZE}_batch_size\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"* Training\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "\n",
    "    print(\"* Saving model\")\n",
    "    _epoch_save_path = f\"{save_path}_checkpoint_{epoch + 1}.pth\"\n",
    "    torch.save(model, _epoch_save_path)\n",
    "\n",
    "    print(\"* Calculating metrics for training\")\n",
    "    train_metrics  = evaluate(model, train_loader, device)\n",
    "    print(\"* Calculating metrics for validation\")\n",
    "    val_metrics  = evaluate(model, val_loader, device)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_metrics\"].append(train_metrics)\n",
    "    history[\"val_metrics\"].append(val_metrics)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(\"Train Metrics:\")\n",
    "    for metric_name, value in train_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    for metric_name, value in val_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndividualTransformer(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (l3): Dropout(p=0.1, inplace=False)\n",
       "  (l4): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torch.load('models/models_individual_concatenate_embeddings/distil-bert-base/model_name.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: {'accuracy': 0.9963747592613572, 'roc-auc': 0.9999394228031161, 'brier': 0.002886941324714981, 'c@1': 0.9963747592613572, 'f1': 0.9966365356317007, 'f05u': 0.9961339664663612, 'mean': 0.79839432509745}\n",
      "Val Accuracy: {'accuracy': 0.9909502262443439, 'roc-auc': 0.9996498599439776, 'brier': 0.008421512442230524, 'c@1': 0.9909502262443439, 'f1': 0.9915966386554622, 'f05u': 0.9915966386554622, 'mean': 0.7964429751882953}\n",
      "Test Accuracy: {'accuracy': 0.9898190045248869, 'roc-auc': 0.9991584409499095, 'brier': 0.00840735392105763, 'c@1': 0.9898190045248869, 'f1': 0.9905660377358491, 'f05u': 0.989321608040201, 'mean': 0.7954544890343808}\n"
     ]
    }
   ],
   "source": [
    "# Evaluación final en el conjunto de prueba\n",
    "train_accuracy = evaluate(model, train_loader, device)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "val_accuracy = evaluate(model, val_loader, device)\n",
    "print(f\"Val Accuracy: {val_accuracy}\")\n",
    "test_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
