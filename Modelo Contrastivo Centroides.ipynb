{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modelos Contrastivos (CLIP-like)\n",
    "Entrena un modelo basado en contraste, donde el objetivo es minimizar la distancia entre embeddings de texto humano y maximizar la distancia entre humano y generado por IA.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Permite aprender representaciones robustas.\n",
    "Se puede usar junto con un clasificador simple para la predicción final.\n",
    "Ejemplo de entrenamiento contrastivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "LAYERS_TO_TRAIN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alonso\\Documents\\## UPM\\MASTER\\NLP\\practica\\NLP\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_generated_path = \"pan24-generative-authorship-news/machines\"\n",
    "human_path = \"pan24-generative-authorship-news/human.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*overflowing tokens.*\")\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpaca-7b.jsonl</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>'The Disappearance of Gabby Petito' – A Compre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>Utah State Police Search for Gabby Petito, Tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>\"Gunshots Found in Florida Nature Preserve: A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1.jsonl</td>\n",
       "      <td>vicgalle-gpt2-open-instruct-v1/news-2021-01-01...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0                           alpaca-7b.jsonl   \n",
       "1                           alpaca-7b.jsonl   \n",
       "2                           alpaca-7b.jsonl   \n",
       "3                           alpaca-7b.jsonl   \n",
       "4                           alpaca-7b.jsonl   \n",
       "...                                     ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14127  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14128  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14129  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "14130  vicgalle-gpt2-open-instruct-v1.jsonl   \n",
       "\n",
       "                                                      id  \\\n",
       "0      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "1      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "2      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "3      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "4      alpaca-7b/news-2021-01-01-2021-12-31-bideninau...   \n",
       "...                                                  ...   \n",
       "14126  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14127  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14128  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14129  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "14130  vicgalle-gpt2-open-instruct-v1/news-2021-01-01...   \n",
       "\n",
       "                                                    text  ai_generated  \n",
       "0      Inaugural Address: President Joseph R. Biden J...             1  \n",
       "1      Setting the Record Straight: Fact-Checking the...             1  \n",
       "2      Joe Biden Takes the Oath of Office as 46th Pre...             1  \n",
       "3      Joe Biden Takes Oath as 46th President of Unit...             1  \n",
       "4      Amanda Gorman's Inspiring Poem Celebrates Hope...             1  \n",
       "...                                                  ...           ...  \n",
       "14126  'The Disappearance of Gabby Petito' – A Compre...             1  \n",
       "14127  Utah State Police Search for Gabby Petito, Tra...             1  \n",
       "14128  McKenna's Lost Friend: Debunking the Evidence ...             1  \n",
       "14129  \"Gunshots Found in Florida Nature Preserve: A ...             1  \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...             1  \n",
       "\n",
       "[14131 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, id, text = [], [], []\n",
    "\n",
    "# Loop through every file in the directory\n",
    "for filename in os.listdir(ai_generated_path):\n",
    "    # Check if the file is a JSONL file\n",
    "    if filename.endswith('.jsonl'):\n",
    "        filepath = os.path.join(ai_generated_path, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                # Each line is a separate JSON object\n",
    "                data = json.loads(line)\n",
    "                model.append(filename)\n",
    "                id.append(data['id'])\n",
    "                text.append(data['text'])\n",
    "\n",
    "df_generated = pd.DataFrame({'model': model, 'id': id, 'text': text, 'ai_generated': 1})\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Fact check: Biden inauguration impacted by pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Highlights from Joe Biden's 2021 inauguration\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Biden takes the helm, appeals for unity to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>'The Hill We Climb': Read Amanda Gorman's inau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Human</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                                 id  \\\n",
       "0     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "2     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "3     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "4     Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "...     ...                                                ...   \n",
       "1082  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1083  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1084  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1085  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "1086  Human  articles-cleaned-truncated/news-2021-01-01-202...   \n",
       "\n",
       "                                                   text  ai_generated  \n",
       "0     Inaugural Address by President Joseph R. Biden...             0  \n",
       "1     Fact check: Biden inauguration impacted by pan...             0  \n",
       "2     Highlights from Joe Biden's 2021 inauguration\\...             0  \n",
       "3     Biden takes the helm, appeals for unity to tak...             0  \n",
       "4     'The Hill We Climb': Read Amanda Gorman's inau...             0  \n",
       "...                                                 ...           ...  \n",
       "1082  How amateur detectives on social media helped ...             0  \n",
       "1083  Authorities searching for missing 22-year-old ...             0  \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0  \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0  \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0  \n",
       "\n",
       "[1087 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id, text = [], []\n",
    "\n",
    "with open(human_path, 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        # Each line is a separate JSON object\n",
    "        data = json.loads(line)\n",
    "        id.append(data['id'])\n",
    "        text.append(data['text'])\n",
    "\n",
    "df_human = pd.DataFrame({'model': 'Human', 'id': id, 'text': text, 'ai_generated': 0})\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ai_generated</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Setting the Record Straight: Fact-Checking the...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden Takes the Oath of Office as 46th Pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joe Biden Takes Oath as 46th President of Unit...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amanda Gorman's Inspiring Poem Celebrates Hope...</td>\n",
       "      <td>1</td>\n",
       "      <td>alpaca-7b/news-2021-01-01-2021-12-31-bideninau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>How amateur detectives on social media helped ...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Authorities searching for missing 22-year-old ...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Did the Internet Actually Help Find Gabby Peti...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>articles-cleaned-truncated/news-2021-01-01-202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ai_generated  \\\n",
       "0     Inaugural Address: President Joseph R. Biden J...             1   \n",
       "1     Setting the Record Straight: Fact-Checking the...             1   \n",
       "2     Joe Biden Takes the Oath of Office as 46th Pre...             1   \n",
       "3     Joe Biden Takes Oath as 46th President of Unit...             1   \n",
       "4     Amanda Gorman's Inspiring Poem Celebrates Hope...             1   \n",
       "...                                                 ...           ...   \n",
       "1082  How amateur detectives on social media helped ...             0   \n",
       "1083  Authorities searching for missing 22-year-old ...             0   \n",
       "1084  Univ. of Wisconsin Oshkosh student helping Gab...             0   \n",
       "1085  Did the Internet Actually Help Find Gabby Peti...             0   \n",
       "1086  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "\n",
       "                                                     id  \n",
       "0     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "1     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "2     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "3     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "4     alpaca-7b/news-2021-01-01-2021-12-31-bideninau...  \n",
       "...                                                 ...  \n",
       "1082  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1083  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1084  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1085  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "1086  articles-cleaned-truncated/news-2021-01-01-202...  \n",
       "\n",
       "[15218 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_generated, df_human])[['text', 'ai_generated', 'id']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data - Combinaciones únicamente del mismo id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9506, 4)\n",
      "val shape: (1904, 4)\n",
      "test shape: (3808, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "test_size = 0.25\n",
    "val_size = 0.125\n",
    "_adjusted_val_size = val_size / (1 - test_size)\n",
    "\n",
    "# Extraer el segundo y tercer segmento de los IDs\n",
    "df['base_id'] = df['id'].apply(lambda x: '/'.join(x.split('/')[1:]))  # Coger los ids sin la parte que identifica al autor del fragmento de texto.\n",
    "\n",
    "# Paso 1: Dividir los datos según los `base_id`\n",
    "base_ids = df['base_id'].unique()\n",
    "train_base_ids, test_base_ids = train_test_split(base_ids, test_size=test_size, random_state=1337)\n",
    "train_base_ids, val_base_ids = train_test_split(train_base_ids, test_size=_adjusted_val_size, random_state=1337) \n",
    "\n",
    "# Crear DataFrames por conjunto\n",
    "train = df[df['base_id'].isin(train_base_ids)]\n",
    "val = df[df['base_id'].isin(val_base_ids)]\n",
    "test = df[df['base_id'].isin(test_base_ids)]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"val shape: {val.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combinations_within_id(df):\n",
    "    # Lista para almacenar las combinaciones de cada `base_id`\n",
    "    combinations = []\n",
    "    \n",
    "    # Iterar sobre cada `base_id`\n",
    "    for base_id, group in df.groupby('base_id'):\n",
    "        # Filtrar textos humanos e IA dentro del grupo\n",
    "        df_human = group[group['ai_generated'] == 0][['text']].reset_index(drop=True)\n",
    "        df_ia = group[group['ai_generated'] == 1][['text']].reset_index(drop=True)\n",
    "        \n",
    "        # Producto cartesiano dentro del `base_id`\n",
    "        cartesian_df = df_human.merge(df_ia, how='cross', suffixes=('_human', '_ia'))\n",
    "        cartesian_df = cartesian_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Crear las dos disposiciones\n",
    "        total_combinations = len(cartesian_df)\n",
    "        \n",
    "        half_1 = cartesian_df.iloc[:total_combinations // 2].copy()\n",
    "        half_1['comment_text_1'] = half_1['text_human']\n",
    "        half_1['comment_text_2'] = half_1['text_ia']\n",
    "        half_1['list'] = 0  # Etiqueta 0\n",
    "        \n",
    "        half_2 = cartesian_df.iloc[total_combinations // 2:].copy()\n",
    "        half_2['comment_text_1'] = half_2['text_ia']\n",
    "        half_2['comment_text_2'] = half_2['text_human']\n",
    "        half_2['list'] = 1  # Etiqueta 1\n",
    "        \n",
    "        # Combinar y agregar al resultado final\n",
    "        balanced_df = pd.concat([half_1, half_2], ignore_index=True)\n",
    "        combinations.append(balanced_df)\n",
    "    \n",
    "    # Concatenar todas las combinaciones y barajar\n",
    "    return pd.concat(combinations, ignore_index=True).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar combinaciones restringidas por `id` para cada conjunto\n",
    "train = create_combinations_within_id(train)\n",
    "val = create_combinations_within_id(val)\n",
    "test = create_combinations_within_id(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (8827, 5) / Text on comment_text_1 is human-generated: 4074 - Text on comment_text_2 is human-generated: 4753\n",
      "val shape: (1768, 5) / Text on comment_text_1 is human-generated: 816 - Text on comment_text_2 is human-generated: 952\n",
      "test shape: (3536, 5) / Text on comment_text_1 is human-generated: 1632 - Text on comment_text_2 is human-generated: 1904\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions\n",
    "print(f\"train shape: {train.shape} / Text on comment_text_1 is human-generated: {train['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {train['list'].value_counts()[1]}\")\n",
    "print(f\"val shape: {val.shape} / Text on comment_text_1 is human-generated: {val['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {val['list'].value_counts()[1]}\")\n",
    "print(f\"test shape: {test.shape} / Text on comment_text_1 is human-generated: {test['list'].value_counts()[0]} - Text on comment_text_2 is human-generated: {test['list'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Tokenizador y modelo\n",
    "model_name = \"Lau123/distilbert-base-uncased-detect_ai_generated_text\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# individual_model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "individual_model =  BertModel.from_pretrained(model_name).from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Configuración del dispositivo y optimizador\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# individual_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight: requires_grad = False\n",
      "embeddings.position_embeddings.weight: requires_grad = False\n",
      "embeddings.token_type_embeddings.weight: requires_grad = False\n",
      "embeddings.LayerNorm.weight: requires_grad = False\n",
      "embeddings.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.0.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.0.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.0.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.0.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.0.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.0.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.0.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.0.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.0.output.dense.weight: requires_grad = False\n",
      "encoder.layer.0.output.dense.bias: requires_grad = False\n",
      "encoder.layer.0.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.0.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.1.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.1.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.1.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.1.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.1.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.1.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.1.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.1.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.1.output.dense.weight: requires_grad = False\n",
      "encoder.layer.1.output.dense.bias: requires_grad = False\n",
      "encoder.layer.1.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.1.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.2.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.2.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.2.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.2.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.2.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.2.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.2.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.2.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.2.output.dense.weight: requires_grad = False\n",
      "encoder.layer.2.output.dense.bias: requires_grad = False\n",
      "encoder.layer.2.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.2.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.3.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.3.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.3.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.3.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.3.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.3.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.3.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.3.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.3.output.dense.weight: requires_grad = False\n",
      "encoder.layer.3.output.dense.bias: requires_grad = False\n",
      "encoder.layer.3.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.3.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.4.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.4.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.4.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.4.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.4.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.4.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.4.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.4.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.4.output.dense.weight: requires_grad = False\n",
      "encoder.layer.4.output.dense.bias: requires_grad = False\n",
      "encoder.layer.4.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.4.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.5.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.5.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.5.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.5.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.5.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.5.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.5.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.5.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.5.output.dense.weight: requires_grad = False\n",
      "encoder.layer.5.output.dense.bias: requires_grad = False\n",
      "encoder.layer.5.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.5.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.6.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.6.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.6.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.6.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.6.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.6.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.6.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.6.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.6.output.dense.weight: requires_grad = False\n",
      "encoder.layer.6.output.dense.bias: requires_grad = False\n",
      "encoder.layer.6.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.6.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.7.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.7.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.7.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.7.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.7.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.7.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.7.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.7.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.7.output.dense.weight: requires_grad = False\n",
      "encoder.layer.7.output.dense.bias: requires_grad = False\n",
      "encoder.layer.7.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.7.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.8.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.8.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.8.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.8.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.8.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.8.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.8.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.8.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.8.output.dense.weight: requires_grad = False\n",
      "encoder.layer.8.output.dense.bias: requires_grad = False\n",
      "encoder.layer.8.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.8.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.9.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.9.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.9.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.9.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.9.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.9.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.9.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.9.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.9.output.dense.weight: requires_grad = False\n",
      "encoder.layer.9.output.dense.bias: requires_grad = False\n",
      "encoder.layer.9.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.9.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.10.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.10.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.10.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.10.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.10.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.10.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.10.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.10.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.10.output.dense.weight: requires_grad = False\n",
      "encoder.layer.10.output.dense.bias: requires_grad = False\n",
      "encoder.layer.10.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.10.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.11.attention.self.query.weight: requires_grad = False\n",
      "encoder.layer.11.attention.self.query.bias: requires_grad = False\n",
      "encoder.layer.11.attention.self.key.weight: requires_grad = False\n",
      "encoder.layer.11.attention.self.key.bias: requires_grad = False\n",
      "encoder.layer.11.attention.self.value.weight: requires_grad = False\n",
      "encoder.layer.11.attention.self.value.bias: requires_grad = False\n",
      "encoder.layer.11.attention.output.dense.weight: requires_grad = False\n",
      "encoder.layer.11.attention.output.dense.bias: requires_grad = False\n",
      "encoder.layer.11.attention.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.11.attention.output.LayerNorm.bias: requires_grad = False\n",
      "encoder.layer.11.intermediate.dense.weight: requires_grad = False\n",
      "encoder.layer.11.intermediate.dense.bias: requires_grad = False\n",
      "encoder.layer.11.output.dense.weight: requires_grad = False\n",
      "encoder.layer.11.output.dense.bias: requires_grad = False\n",
      "encoder.layer.11.output.LayerNorm.weight: requires_grad = False\n",
      "encoder.layer.11.output.LayerNorm.bias: requires_grad = False\n",
      "pooler.dense.weight: requires_grad = True\n",
      "pooler.dense.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# # Freeze all layers except the classifier layer\n",
    "# for name, param in individual_model.named_parameters():\n",
    "#     if name != \"classifier.weight\" and name != \"classifier.bias\":\n",
    "#         param.requires_grad = False\n",
    "\n",
    "for param in individual_model.parameters():\n",
    "    param.requires_grad = False\n",
    "if LAYERS_TO_TRAIN > 0:\n",
    "    for layer in individual_model.encoder.layer[-LAYERS_TO_TRAIN:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "for param in individual_model.pooler.dense.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify that only the classifier layer is trainable\n",
    "for name, param in individual_model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def contrastive_loss(embeddings1, embeddings2, labels, margin=0.5):\n",
    "    sim = cosine_similarity(embeddings1, embeddings2)\n",
    "    loss = torch.mean(labels * (1 - sim) + (1 - labels) * torch.clamp(sim - margin, min=0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerContrastive(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (l3): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerContrastive(torch.nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(TransformerContrastive, self).__init__()\n",
    "        self.l1 = bert_model  # Modelo BERT o similar\n",
    "        self.l2 = torch.nn.Linear(768, 768)  # Proyección del embedding\n",
    "        self.l3 = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, ids_0, mask_0, token_type_ids_0, ids_1, mask_1, token_type_ids_1):\n",
    "        # Generar embeddings para ambos textos\n",
    "        embed_a = self.l1(ids_0, attention_mask=mask_0, token_type_ids=token_type_ids_0).last_hidden_state[:, 0]\n",
    "        embed_b = self.l1(ids_1, attention_mask=mask_1, token_type_ids=token_type_ids_1).last_hidden_state[:, 0]\n",
    "\n",
    "        # Proyección a un espacio latente (opcional, pero puede mejorar resultados)\n",
    "        embed_a = F.gelu(self.l3(self.l2(embed_a)))\n",
    "        embed_b = F.gelu(self.l3(self.l2(embed_b)))\n",
    "\n",
    "        return embed_a, embed_b  # Devuelve los embeddings de ambos textos\n",
    "\n",
    "# Inicializar modelo\n",
    "model = TransformerContrastive(individual_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alonso\\Documents\\## UPM\\MASTER\\NLP\\practica\\NLP\\venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embed_a, embed_b, label):\n",
    "        # Distancia euclidiana entre embeddings\n",
    "        distance = torch.norm(embed_a - embed_b, p=2, dim=1)\n",
    "\n",
    "        # Pérdida contrastiva\n",
    "        loss = label * distance.pow(2) + (1 - label) * F.relu(self.margin - distance).pow(2)\n",
    "        return loss.mean()\n",
    "\n",
    "# loss_fn = torch.nn.BCELoss()\n",
    "loss_fn = ContrastiveLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text_1 = dataframe.comment_text_1\n",
    "        self.comment_text_2 = dataframe.comment_text_2\n",
    "        self.targets = self.data.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text_1 = str(self.comment_text_1[index])\n",
    "        comment_text_1 = \" \".join(comment_text_1.split())\n",
    "        comment_text_2 = str(self.comment_text_2[index])\n",
    "        comment_text_2 = \" \".join(comment_text_2.split())\n",
    "        inputs0 = self.tokenizer(comment_text_1, \n",
    "                                comment_text_2, \n",
    "                                max_length=self.max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                # truncation=\"only_second\",\n",
    "                                # truncation=\"only_first\",\n",
    "                                # truncation=\"longest_first\",\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_token_type_ids=True,)\n",
    "                                # return_overflowing_tokens=True)\n",
    "                                # return_overflowing_tokens=False)\n",
    "        inputs1 = self.tokenizer(comment_text_1,\n",
    "                                max_length=self.max_len,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_token_type_ids=True,)\n",
    "        return {\n",
    "            'ids_0': torch.tensor(inputs0.input_ids, dtype=torch.long),\n",
    "            'mask_0': torch.tensor(inputs0.attention_mask, dtype=torch.long),\n",
    "            'token_type_ids_0': torch.tensor(inputs0.token_type_ids, dtype=torch.long),\n",
    "            'ids_1': torch.tensor(inputs1.input_ids, dtype=torch.long),\n",
    "            'mask_1': torch.tensor(inputs1.attention_mask, dtype=torch.long),\n",
    "            'token_type_ids_1': torch.tensor(inputs1.token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia el dataset\n",
    "train_dataset = CustomDataset(dataframe=train, tokenizer=tokenizer, max_len=512)\n",
    "val_dataset = CustomDataset(dataframe=val, tokenizer=tokenizer, max_len=512)\n",
    "test_dataset = CustomDataset(dataframe=test, tokenizer=tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_at_1(targets, preds):\n",
    "    \"\"\"\n",
    "    Calculates the C@1 metric:\n",
    "    - Non-answers (predictions marked as -1) are given a score of 0.5.\n",
    "    - Remaining cases are scored based on accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        targets (np.array): Ground truth labels.\n",
    "        preds (np.array): Predictions, where -1 indicates a non-answer.\n",
    "    \n",
    "    Returns:\n",
    "        float: C@1 metric.\n",
    "    \"\"\"\n",
    "    correct = (targets == preds)  # Boolean array for correct predictions\n",
    "    unanswered = preds == -1     # Boolean array for non-answers\n",
    "    \n",
    "    num_correct = correct.sum()\n",
    "    num_total = len(targets)\n",
    "    num_unanswered = unanswered.sum()\n",
    "    \n",
    "    return (num_correct + num_unanswered * 0.5) / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, brier_score_loss, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(f\"Batch {i+1}/{len(loader)}\")\n",
    "        labels = batch['labels'].unsqueeze(1).to(device).float()\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        embed_a, embed_b = model(**batch)\n",
    "\n",
    "        loss = loss_fn(embed_a, embed_b, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i == 2:\n",
    "            break\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Función de evaluación para el modelo contrastivo\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_distances, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # Separar etiquetas y mover datos al dispositivo\n",
    "            labels = batch['labels'].float().to(device)\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "\n",
    "            # Generar embeddings\n",
    "            embed_a, embed_b = model(\n",
    "                ids_0=batch['ids_0'], \n",
    "                mask_0=batch['mask_0'], \n",
    "                token_type_ids_0=batch['token_type_ids_0'],\n",
    "                ids_1=batch['ids_1'], \n",
    "                mask_1=batch['mask_1'], \n",
    "                token_type_ids_1=batch['token_type_ids_1']\n",
    "            )\n",
    "\n",
    "            # Calcular distancias euclidianas\n",
    "            distances = torch.norm(embed_a - embed_b, p=2, dim=1)\n",
    "\n",
    "            # Guardar distancias y etiquetas\n",
    "            all_distances.extend(distances.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convertir a numpy arrays\n",
    "    all_distances = np.array(all_distances)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mean_positive_distance = all_distances[all_labels == 1].mean()  # Donde el humano es el segundo texto\n",
    "    mean_negative_distance = all_distances[all_labels == 0].mean()  # Donde el humano es el primer texto\n",
    "    distance_ratio = mean_positive_distance / (mean_negative_distance + 1e-6)  # Relación entre las dos\n",
    "\n",
    "    # ROC AUC para evaluar la separación entre las clases\n",
    "    roc_auc = roc_auc_score(all_labels, -all_distances)  # Menores distancias => más similares\n",
    "\n",
    "    metrics = {\n",
    "        \"mean_positive_distance\": mean_positive_distance,\n",
    "        \"mean_negative_distance\": mean_negative_distance,\n",
    "        \"distance_ratio\": distance_ratio,\n",
    "        \"roc_auc\": roc_auc,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/5\n",
      "* Training\n",
      "Batch 1/35\n",
      "Batch 2/35\n",
      "Batch 3/35\n",
      "* Saving model\n",
      "* Calculating metrics for training\n",
      "* Calculating metrics for validation\n",
      "Epoch 1/5\n",
      "Train Loss: 3.0727\n",
      "Train Metrics:\n",
      "  mean_positive_distance: 3.4276\n",
      "  mean_negative_distance: 3.0667\n",
      "  distance_ratio: 1.1177\n",
      "  roc_auc: 0.4225\n",
      "Validation Metrics:\n",
      "  mean_positive_distance: 3.4169\n",
      "  mean_negative_distance: 3.0563\n",
      "  distance_ratio: 1.1180\n",
      "  roc_auc: 0.4052\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_metrics\": [],\n",
    "    \"val_metrics\": []\n",
    "}\n",
    "\n",
    "save_path = f\"models/models_contrastive/fine_tuned_model_{EPOCHS}_epochs_{LEARNING_RATE}_lr_{LAYERS_TO_TRAIN}_layers_{BATCH_SIZE}_batch_size\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"* Training\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "\n",
    "    print(\"* Saving model\")\n",
    "    _epoch_save_path = f\"{save_path}_checkoint_{epoch + 1}.pth\"\n",
    "    torch.save(model, _epoch_save_path)\n",
    "\n",
    "    print(\"* Calculating metrics for training\")\n",
    "    train_metrics = evaluate(model, train_loader, device)\n",
    "    print(\"* Calculating metrics for validation\")\n",
    "    val_metrics = evaluate(model, val_loader, device)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_metrics\"].append(train_metrics)\n",
    "    history[\"val_metrics\"].append(val_metrics)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(\"Train Metrics:\")\n",
    "    for metric_name, value in train_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    for metric_name, value in val_metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/35\n",
      "Batch 2/35\n",
      "Batch 3/35\n",
      "Batch 4/35\n",
      "Batch 5/35\n",
      "Batch 6/35\n",
      "Batch 7/35\n",
      "Batch 8/35\n",
      "Batch 9/35\n",
      "Batch 10/35\n",
      "Batch 11/35\n",
      "Batch 12/35\n",
      "Batch 13/35\n",
      "Batch 14/35\n",
      "Batch 15/35\n",
      "Batch 16/35\n",
      "Batch 17/35\n",
      "Batch 18/35\n",
      "Batch 19/35\n",
      "Batch 20/35\n",
      "Batch 21/35\n",
      "Batch 22/35\n",
      "Batch 23/35\n",
      "Batch 24/35\n",
      "Batch 25/35\n",
      "Batch 26/35\n",
      "Batch 27/35\n",
      "Batch 28/35\n",
      "Batch 29/35\n",
      "Batch 30/35\n",
      "Batch 31/35\n",
      "Batch 32/35\n",
      "Batch 33/35\n",
      "Batch 34/35\n",
      "Batch 35/35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc  # Para recolección de basura\n",
    "\n",
    "human_text_tuples = [(text, text, 0) for text in train['text_human']]\n",
    "human_df = pd.DataFrame(human_text_tuples, columns=['comment_text_1', 'comment_text_2', 'list'])\n",
    "human_dataset = CustomDataset(dataframe=human_df, tokenizer=tokenizer, max_len=512)\n",
    "human_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "human_embeddings = []\n",
    "for i, batch in enumerate(human_loader):\n",
    "    print(f\"Batch {i+1}/{len(human_loader)}\")\n",
    "    labels = batch['labels'].unsqueeze(1).to(device).float()\n",
    "    batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "    embed_a, _ = model(**batch)\n",
    "    human_embeddings.extend(embed_a.cpu())\n",
    "\n",
    "stacked = torch.stack(human_embeddings)\n",
    "prototype_human = stacked.mean(dim=0).to(device)\n",
    "\n",
    "\n",
    "del human_embeddings, batch, embed_a, labels\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de evaluación para la clasificación final\n",
    "def evaluate(model, loader, prototype_human, device):\n",
    "    model.eval()\n",
    "    preds, targets, probabilities = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            print(f\"Batch {i+1}/{len(loader)}\")\n",
    "            labels = batch['labels'].unsqueeze(1).float()\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            embed_a, embed_b = model(**batch)\n",
    "            similarity_a_human = torch.cosine_similarity(embed_a, prototype_human.unsqueeze(0), dim=1)\n",
    "            similarity_b_human = torch.cosine_similarity(embed_b, prototype_human.unsqueeze(0), dim=1)\n",
    "            predictions = (similarity_a_human <= similarity_b_human).int()  # 1 for sim_b > sim_a, else 0\n",
    "            prob = similarity_b_human - similarity_a_human\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(prob.cpu().numpy())\n",
    "    \n",
    "    targets = np.array(targets).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    probabilities = np.array(probabilities).flatten()\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"Calculating roc_auc\")\n",
    "    roc_auc = roc_auc_score(targets, probabilities)\n",
    "    # print(\"Calculating brier\")\n",
    "    # brier = brier_score_loss(targets, probabilities)\n",
    "    print(\"Calculating f1\")\n",
    "    f1 = f1_score(targets, preds)\n",
    "    print(\"Calculating f05u\")\n",
    "    f05u = fbeta_score(targets, preds, beta=0.5)\n",
    "    print(\"Calculating c@1\")\n",
    "    c1 = c_at_1(targets, preds)\n",
    "    print(\"Calculating mean\")\n",
    "    # mean = np.mean([roc_auc, brier, c1, f1, f05u])\n",
    "    mean = np.mean([roc_auc, c1, f1, f05u])\n",
    "    print(\"Calcualtin accuracy\")\n",
    "    accuracy = accuracy_score(targets, preds)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"roc-auc\": roc_auc,\n",
    "        # \"brier\": brier,\n",
    "        \"c@1\": c1,\n",
    "        \"f1\": f1,\n",
    "        \"f05u\": f05u,\n",
    "        \"mean\": mean,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Batch 35/14\n",
      "Calculating roc_auc\n",
      "Calculating f1\n",
      "Calculating f05u\n",
      "Calculating c@1\n",
      "Calculating mean\n",
      "Calcualtin accuracy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to dict.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluación final en el conjunto de prueba\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# train_accuracy = evaluate(model, train_loader, prototype_human, device)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(f\"Train Accuracy: {train_accuracy:.4f}\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# val_accuracy = evaluate(model, val_loader, prototype_human, device)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(f\"Val Accuracy: {val_accuracy:.4f}\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, prototype_human, device)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to dict.__format__"
     ]
    }
   ],
   "source": [
    "# Evaluación final en el conjunto de prueba\n",
    "# train_accuracy = evaluate(model, train_loader, prototype_human, device)\n",
    "# print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "# val_accuracy = evaluate(model, val_loader, prototype_human, device)\n",
    "# print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "test_accuracy = evaluate(model, test_loader, prototype_human, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.46153846153846156,\n",
       " 'roc-auc': 0.5179647916151755,\n",
       " 'c@1': 0.46153846153846156,\n",
       " 'f1': 0.0,\n",
       " 'f05u': 0.0,\n",
       " 'mean': 0.24487581328840927}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
